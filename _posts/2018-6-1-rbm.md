---
layout: post
title: Restricted Boltzmann Machines Part 1, Markov Random Fields
---

In this series of posts, I will give an introduction to restricted Boltzmann machines, eventually discussing their implementation and applications in machine learning. Before getting to applications, we will recall some of the main ideas of the underlying probability/statistical learning theory. 

## Graphical models and the local Markov property

Markov random fields (MRFs) are a specific kind of probablistic model called a *graphical model*. Roughly speaking, a graphical model is a graph whose vertices correspond to random variables (usually from the same distribution) and whose edges carry information about conditional dependence of those random variables. Graphical models are useful for studying joint probability distributions with many variables because they generally have fewer parameters than alternatives.

Before giving the precise definition of MRFs, let's recall some background. Random variables \\( x,y \\) are *conditionally independent given* \\( z \\) if 
\\[
p(x,y\vert z) = p(x\vert z) p(y\vert z).
\\]
By the definition of conditional probability, this is equivalent to either of the equations
\\[
p(x\vert y,z) = p(x\vert z),\mbox{ or } p(y\vert x,z) = p(y\vert z).
\\]

If you squint, you can interpret Markov chains as directed graphical models. A *Markov chain* is a sequence of random variables \\( x\_{t} \\),  \\( t \\) a positive integer, where every state only depends on the previous state, not earlier ones. This condition is called the *Markov property.* In terms of conditional independence, this is the statement that each \\(x\_{t}\\) is conditionally independent of all earlier \\(x\\)'s, given \\( x\_{t-1}\\).  Mathematically, this looks like the second equation above:

\\[
p(x\_{t}\vert x\_{t-1}, x\_{t-2}, \ldots x\_3,x\_2, x\_1) = p(x\_{t}\vert x\_{t-1})
\\]

A Markov chain can be represented by a graph with vertex set \\( V = \mathbb{N} \\) and directed edges from \\(v\_i\\) to \\(v\_{i+1}\\). In the terminology of graph theory, the Markov property for a Markov chain can be rephrased as the more general *local Markov property*.

> A directed graphical model has the **local Markov property** if each random variable \\(x\_{v}\\) is conditionally independent of all its non-descendant random variables (there is no directed path from \\(v\\) to the vertex), given the random variables \\(x\_w\\) such that \\(w\\) is a parent of \\(v\\) (there is a directed edge from \\(w\\) to \\(v\\)).

This more general definition makes sense on any acyclic directed graph, not just the one used for Markov chains (i.e. it is not necessarily a sequence of variables indexed by time). A directed graphical model that satisfies the local Markov property above is called a *Bayesian network*. We won't focus on these models for the rest of this post, but it's worth being aware of them.

We're more interested in *undirected* graphical models that have a similar local Markov property. 

> An undirected graphical model has the **local Markov property** if each random variable \\(x_{v}\\) is conditionally independent of all other random variables, given the random variables \\(x_w\\) such that \\(w\\) is adjacent to \\(v\\) (there is an edge from \\(w\\) to \\(v\\)).

A *MRF* is an undirected graphical model that satisfies the local Markov property. One thing this condition tells us is that - intuitively - it will be easier to study the probability distribution of sparser graphical models, because conditional probabilities will simplify as in the previous equation.

## MRFs in more detail

Now that we have a precise definition of MRFs, we can study them in a bit more detail. 

Recall that a *clique* in a graph is a subset of vertices \\(C\subseteq V\\) such that all pairs of distinct vertices in \\(C\\) are adjacent.  A clique is maximal if it is not contained in any larger clique. 

Let's assume that the joint probability distribution of our MRF is strictly positive (no state has probability 0).  In this case we can apply the  *Hammersley–Clifford Theorem* which says a strictly positive distribution \\( p\\) is a MRF on a graph \\( G \\) iff it can be *factored over G*. \\( p\\) can be *factored over G* means

\\[
p(x) = \frac{1}{Z} \prod_C \psi_C(x)
\\]
where  \\(\psi_C \colon C \to \mathbb{R} \\) are positive functions, and the product is over the set of all maximal cliques in \\(G\\) (\\(Z\\) is the partition function). It is common to write \\(\psi_C(x)\\), understanding that the function only depends on \\(x\_c\\) for \\(c\in C\\).  It's worth mentioning here that the problem of [enumerating all maximal cliques in a graph](https://en.wikipedia.org/wiki/Clique_problem#Listing_all_maximal_cliques) is a classical problem.

The \\(\psi_C\\) are strictly positive since \\(p\\) is, so we can rewrite
\\[
\prod_C \psi_C = \exp\left(\sum_C\ln \psi_C\right).
\\]
A probability distribution of this form is called a *Gibbs distribution* or *Boltzmann distribution*, so one can interpret the Hammersley–Clifford Theorem as saying that Gibbs distributions are equivalent to (positive) MRF's.

The function \\( E = -\sum_C\ln \psi_C \\) is the *energy* of the Gibbs distribution. It's perhaps worth noting that energy is related to the information content \\(I(x)\\) by the equation
\\[
I(x) = -\ln p(x) = - \sum_C\ln\psi_c(x) + \ln Z  = E(x) + \ln Z.
\\]
(taking expectation of the left side gives Shannon entropy of \\(p\\)).

## Maximum likelihood for MRF

Finally, let's describe the general theory of training a MRF. In practice, doing this requires choosing a family of energy functions that are parameterized by some finite list of variables. In theory, we consider \\(E\\) to be in some large family of functions.  With the choice of \\(E\\) in mind, we now have a conditional probability
\\[
p(x|E) = \frac{1}{Z}e^{-E(X)}
\\]
Training a MRF means solving the maximum-likelihood problem 
\\[
\text{ argmax}_{E}\left( \prod_i p(x_i|E) \right)
\\]
where \\(x_1,\ldots,x_n\\) is set of iid samples from the true probability distribution that we want \\(p\\) to model.

For instance, if we wanted to model a distribution of black and white images (maybe sketches) of cats and each image was 28x28 pixels, then our MRF would have 784 vertices/random variables. In order to solve the maximum-likelihood problem for this model, we would need to make several assumptions, such as fixing a reasonable parameterization of the energy functions.

## Part 2

In part 2 we will introduct the energy function for a Boltzmann machines (a certain type of MRF) and discuss the details of how likelihood is maximized in practice.

### References

One of the main references I will be following is 

A. Fischer, C. Igel. "Training restricted Boltzmann machines: An introduction." *Pattern Recognition*, 47 (2014).


